{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Audio Explorer docs site! Audio Explorer helps in audio data discovery and labelling by utilising unsupervised and supervised machine learning - and good deal of statistics with digital signal processing.","title":"Home"},{"location":"#welcome-to-audio-explorer-docs-site","text":"Audio Explorer helps in audio data discovery and labelling by utilising unsupervised and supervised machine learning - and good deal of statistics with digital signal processing.","title":"Welcome to Audio Explorer docs site!"},{"location":"about/","text":"About Hi, I'm Lukasz! I am a software engineer and scientist. Why Audio Explorer? Manual labelling of audio is time consuming and error prone. With this tool we aim to augment user by allowing to easily navigate recordings and label selected audio pieces. Instead of looking at raw audio, we extract number of audio features from each sample. The latter typically consists of dozens of calculated values (features), which would be impossible to visualise (e.g. 20 features per sample effectively means 20-dimensional space). Audio Explorer allows to compute over 100 features per audio fragment. How do we achieve that? The program computes audio features per short fragments of submitted audio piece and then finds projection to 2-dimensional space by using linear or non-linear dimensionality reduction . Audio fragments are then represented as points; similar sample will be close together, while those which are different further apart. Acknowledgement My special thanks to: AWS Cloud Credits for Research for supporting the project! Thanks to AWS I could rapidly prototype the models and the app itself. My colleagues from RSPB who have supplied the audio recordings and supported along the way. Cheers!","title":"About"},{"location":"about/#about","text":"Hi, I'm Lukasz! I am a software engineer and scientist.","title":"About"},{"location":"about/#why-audio-explorer","text":"Manual labelling of audio is time consuming and error prone. With this tool we aim to augment user by allowing to easily navigate recordings and label selected audio pieces. Instead of looking at raw audio, we extract number of audio features from each sample. The latter typically consists of dozens of calculated values (features), which would be impossible to visualise (e.g. 20 features per sample effectively means 20-dimensional space). Audio Explorer allows to compute over 100 features per audio fragment.","title":"Why Audio Explorer?"},{"location":"about/#how-do-we-achieve-that","text":"The program computes audio features per short fragments of submitted audio piece and then finds projection to 2-dimensional space by using linear or non-linear dimensionality reduction . Audio fragments are then represented as points; similar sample will be close together, while those which are different further apart.","title":"How do we achieve that?"},{"location":"about/#acknowledgement","text":"My special thanks to: AWS Cloud Credits for Research for supporting the project! Thanks to AWS I could rapidly prototype the models and the app itself. My colleagues from RSPB who have supplied the audio recordings and supported along the way. Cheers!","title":"Acknowledgement"},{"location":"app_description/","text":"Audio Explorer Copyright 2019 Lukasz Tracewski Audio Explorer helps in audio data discovery and labelling by utilising unsupervised and supervised machine learning - and good deal of statistics with digital signal processing. Documentation Check the docs to learn about the program. Problem reports and feedback Please post an issue on GitHub project page .","title":"App description"},{"location":"app_description/#audio-explorer","text":"Copyright 2019 Lukasz Tracewski Audio Explorer helps in audio data discovery and labelling by utilising unsupervised and supervised machine learning - and good deal of statistics with digital signal processing.","title":"Audio Explorer"},{"location":"app_description/#documentation","text":"Check the docs to learn about the program.","title":"Documentation"},{"location":"app_description/#problem-reports-and-feedback","text":"Please post an issue on GitHub project page .","title":"Problem reports and feedback"},{"location":"audio_embedding/","text":"Audio embedding Audio features Given audio fragment, thee following features are computed: Frequency statistics: mean, median, first, third and inter quartile Pitch statistics: mean, median, first, third and inter quartile Chroma : short-term pitch profile Linear Predictor Coefficients ( LPC ) Line Spectral Frequency ( LSF ) coefficients Mel-Frequency Cepstral Coefficients ( MFCC ) Octave Band Signal Intensity (OBSI) Spectral crest factor per band Decrease: average spectral slope Flatness: spectral flatness using the ratio between geometric and arithmetic mean Flux: flux of spectrum between consecutives frames Rolloff: frequency so that 99% of the energy is contained below Variation: normalized correlation of spectrum between consecutive frames Dimensionality reduction Dimensionality reduction techniques reduce number of variables by projecting them to a lower-dimensional space. The aim in our case is to retain as much as possible of original information, while enjoying exploration of the data in much in familiar 2D space. We're looking at following methods: Uniform Manifold Approximation and Projection t-Distributed Stochastic Neighbor embedding Principal Component Analysis Kernel Principal Component Analysis Factor Analysis Independent Component Analysis Isomap: Isometric Mapping Spectral embedding Locally Linear Embedding","title":"Audio embedding"},{"location":"audio_embedding/#audio-embedding","text":"","title":"Audio embedding"},{"location":"audio_embedding/#audio-features","text":"Given audio fragment, thee following features are computed: Frequency statistics: mean, median, first, third and inter quartile Pitch statistics: mean, median, first, third and inter quartile Chroma : short-term pitch profile Linear Predictor Coefficients ( LPC ) Line Spectral Frequency ( LSF ) coefficients Mel-Frequency Cepstral Coefficients ( MFCC ) Octave Band Signal Intensity (OBSI) Spectral crest factor per band Decrease: average spectral slope Flatness: spectral flatness using the ratio between geometric and arithmetic mean Flux: flux of spectrum between consecutives frames Rolloff: frequency so that 99% of the energy is contained below Variation: normalized correlation of spectrum between consecutive frames","title":"Audio features"},{"location":"audio_embedding/#dimensionality-reduction","text":"Dimensionality reduction techniques reduce number of variables by projecting them to a lower-dimensional space. The aim in our case is to retain as much as possible of original information, while enjoying exploration of the data in much in familiar 2D space. We're looking at following methods: Uniform Manifold Approximation and Projection t-Distributed Stochastic Neighbor embedding Principal Component Analysis Kernel Principal Component Analysis Factor Analysis Independent Component Analysis Isomap: Isometric Mapping Spectral embedding Locally Linear Embedding","title":"Dimensionality reduction"},{"location":"command_line/","text":"Command Line Interface audiocli is a command line program that helps in extracting audio features and diemnsionality reduction. It's primary purpose is to build offline embeddings for the Audio Explorer. User can create a model with large volume of audio data and then use it to embed new audio files into that space. Usage: audiocli.py [OPTIONS] COMMAND [ARGS]... Options: --quiet Run in a silent mode --help Show this message and exit. Commands: a2f Audio to HDF5 features f2m Features to embedding model m2e Model to embedddings Following options are available: a2f - Audio to Features Usage: audiocli.py a2f [OPTIONS] Audio to HDF5 features Options: -in, --input TEXT Path to audio in WAV format. [required] -out, --output TEXT Output file or directory. If directory does not exist it will be created. The output files will have the same base name as input. -j, --jobs INTEGER Number of jobs to run. Defaults to all cores [default: -1] -c, --config PATH Feature extractor config. -m, --multi Process audio files in parallel. The setting will produce an HDF5 file per input, with the same base name. Large memory footprint. If not set, a single output file will be produced. -f, --format [fixed|table] HDF5 format. Table is slightly slower and requires pytables (will not work outside Python), but allows to read specific columns. --help Show this message and exit. Example: ./audiocli.py a2f --input data/raw/storm_petrels_16k/ --output data/features/features_02s/ --jobs 4 --config audioexplorer/algo_config.ini --multi --format table The program loads complete file into memory, so watch out for memory usage f2m - Features to Model Usage: audiocli.py f2m [OPTIONS] Features to embedding model Options: -in, --input TEXT Path to h5 features. [required] -out, --output TEXT Output directory. -j, --jobs INTEGER Number of jobs to run [default: -1] -a, --algo [umap|tsne|isomap|spectral|loclin|pca|kpca|fa|ica] Embedding to use -p, --grid PATH JSON with grid search parameters for the embedding algo --help Show this message and exit. Example: audiocli.py f2m --input data/features/features_02s/ --output data/models/ --jobs 6 --algo umap --grid data/umap_grid.json --select freq","title":"Command Line Interface"},{"location":"command_line/#command-line-interface","text":"audiocli is a command line program that helps in extracting audio features and diemnsionality reduction. It's primary purpose is to build offline embeddings for the Audio Explorer. User can create a model with large volume of audio data and then use it to embed new audio files into that space. Usage: audiocli.py [OPTIONS] COMMAND [ARGS]... Options: --quiet Run in a silent mode --help Show this message and exit. Commands: a2f Audio to HDF5 features f2m Features to embedding model m2e Model to embedddings Following options are available:","title":"Command Line Interface"},{"location":"command_line/#a2f-audio-to-features","text":"Usage: audiocli.py a2f [OPTIONS] Audio to HDF5 features Options: -in, --input TEXT Path to audio in WAV format. [required] -out, --output TEXT Output file or directory. If directory does not exist it will be created. The output files will have the same base name as input. -j, --jobs INTEGER Number of jobs to run. Defaults to all cores [default: -1] -c, --config PATH Feature extractor config. -m, --multi Process audio files in parallel. The setting will produce an HDF5 file per input, with the same base name. Large memory footprint. If not set, a single output file will be produced. -f, --format [fixed|table] HDF5 format. Table is slightly slower and requires pytables (will not work outside Python), but allows to read specific columns. --help Show this message and exit. Example: ./audiocli.py a2f --input data/raw/storm_petrels_16k/ --output data/features/features_02s/ --jobs 4 --config audioexplorer/algo_config.ini --multi --format table The program loads complete file into memory, so watch out for memory usage","title":"a2f - Audio to Features"},{"location":"command_line/#f2m-features-to-model","text":"Usage: audiocli.py f2m [OPTIONS] Features to embedding model Options: -in, --input TEXT Path to h5 features. [required] -out, --output TEXT Output directory. -j, --jobs INTEGER Number of jobs to run [default: -1] -a, --algo [umap|tsne|isomap|spectral|loclin|pca|kpca|fa|ica] Embedding to use -p, --grid PATH JSON with grid search parameters for the embedding algo --help Show this message and exit. Example: audiocli.py f2m --input data/features/features_02s/ --output data/models/ --jobs 6 --algo umap --grid data/umap_grid.json --select freq","title":"f2m - Features to Model"},{"location":"developer_notes/","text":"Developer notes The web app is hosted on AWS and uses following components: Elastic Beanstalk with Application Load Balancer: orchestration S3: storage Route 53: DNS service Relational Database Service (RDS) with postgresql Secrets Manager: protect secrets (plotly, ipinfo) Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring. Set up development environment To set up your development environment, run the following commands: Fork and clone the Audio Explorer repo . Move into the clone: cd audio-explorer . Create Anaconda environment: conda env create -f environment.yml . Documentation Build docs: mkdocs build Deploy docs to GitHub: mkdocs gh-deploy Deployment Elastic Beanstalk Install AWS CLI for EB: pip install awsebcli Prcedure: Initialise the environment: eb init Create and deploy new instance of type: eb create -i [type] Deploy eb deploy . Hit it to deliver every new chunk. SSH to the machine on Elastic Beanstalk: eb ssh Docker Build docker image: docker image build [path] user/name:latest Example: docker build -t tracek/audio-explorer:latest -t tracek/audio-explorer:0.1 . SSH to the container: sudo docker exec -it [container id] /bin/bash Troubleshooting Problem: Elastic Beanstalk deployment via Docker fails due thin pool getting full. Solution: Use EC2 that has a drive with sufficient space (mind most of EC2 uses EBS volumes) Follow instructions from Server Fault Pull Request Guidelines Use the GitHub flow when proposing contributions to this repository (i.e. create a feature branch and submit a PR against the master branch). How to create pull request is discussed here .","title":"Developer notes"},{"location":"developer_notes/#developer-notes","text":"The web app is hosted on AWS and uses following components: Elastic Beanstalk with Application Load Balancer: orchestration S3: storage Route 53: DNS service Relational Database Service (RDS) with postgresql Secrets Manager: protect secrets (plotly, ipinfo) Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.","title":"Developer notes"},{"location":"developer_notes/#set-up-development-environment","text":"To set up your development environment, run the following commands: Fork and clone the Audio Explorer repo . Move into the clone: cd audio-explorer . Create Anaconda environment: conda env create -f environment.yml .","title":"Set up development environment"},{"location":"developer_notes/#documentation","text":"Build docs: mkdocs build Deploy docs to GitHub: mkdocs gh-deploy","title":"Documentation"},{"location":"developer_notes/#deployment","text":"","title":"Deployment"},{"location":"developer_notes/#elastic-beanstalk","text":"Install AWS CLI for EB: pip install awsebcli Prcedure: Initialise the environment: eb init Create and deploy new instance of type: eb create -i [type] Deploy eb deploy . Hit it to deliver every new chunk. SSH to the machine on Elastic Beanstalk: eb ssh","title":"Elastic Beanstalk"},{"location":"developer_notes/#docker","text":"Build docker image: docker image build [path] user/name:latest Example: docker build -t tracek/audio-explorer:latest -t tracek/audio-explorer:0.1 . SSH to the container: sudo docker exec -it [container id] /bin/bash","title":"Docker"},{"location":"developer_notes/#troubleshooting","text":"Problem: Elastic Beanstalk deployment via Docker fails due thin pool getting full. Solution: Use EC2 that has a drive with sufficient space (mind most of EC2 uses EBS volumes) Follow instructions from Server Fault","title":"Troubleshooting"},{"location":"developer_notes/#pull-request-guidelines","text":"Use the GitHub flow when proposing contributions to this repository (i.e. create a feature branch and submit a PR against the master branch). How to create pull request is discussed here .","title":"Pull Request Guidelines"},{"location":"faq/","text":"Frequently Asked Questions Why bandpass filter only goes to 8000 Hz? The audio you upload is converted to mono-channel 16 kHz which translates to 8 kHz (half of the sampling frequency). Read on Nyquist rate for explanation. My files take long to upload Consider reducing the sampling frequency to 16kHz, number of channels to 1 and compressing the file to e.g. mp3. There is an excellent cross-platform tool called SoX that can help you. If you have a lot of files that you want to process, here's how you can process them in parallel on Linux / Mac: find . -name '*.wav' -type f -print0 | parallel -0 sox --norm {} -r 16000 --channels 1 your-path/{.}.mp3 The command: * Finds all wav * Pipes then to parallel tool that will execute subsequent call in parallel * SoX normalises the audio, resamples to 16 kHz and one channel and then converts to mp3 Read parallel cheat sheet and full manual for details. How to install the software? There are a few approaches: * Start from scratch from the repo * Use Docker image * Check with me about producing a Virtual Machine image with the software. We could use e.g. VirtualBox .","title":"Frequently Asked Questions"},{"location":"faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"faq/#why-bandpass-filter-only-goes-to-8000-hz","text":"The audio you upload is converted to mono-channel 16 kHz which translates to 8 kHz (half of the sampling frequency). Read on Nyquist rate for explanation.","title":"Why bandpass filter only goes to 8000 Hz?"},{"location":"faq/#my-files-take-long-to-upload","text":"Consider reducing the sampling frequency to 16kHz, number of channels to 1 and compressing the file to e.g. mp3. There is an excellent cross-platform tool called SoX that can help you. If you have a lot of files that you want to process, here's how you can process them in parallel on Linux / Mac: find . -name '*.wav' -type f -print0 | parallel -0 sox --norm {} -r 16000 --channels 1 your-path/{.}.mp3 The command: * Finds all wav * Pipes then to parallel tool that will execute subsequent call in parallel * SoX normalises the audio, resamples to 16 kHz and one channel and then converts to mp3 Read parallel cheat sheet and full manual for details.","title":"My files take long to upload"},{"location":"faq/#how-to-install-the-software","text":"There are a few approaches: * Start from scratch from the repo * Use Docker image * Check with me about producing a Virtual Machine image with the software. We could use e.g. VirtualBox .","title":"How to install the software?"},{"location":"getting_started/","text":"Getting started TODO - detailed walkthrough Explore Explanation of app sections. What am I looking at? The scatter plot is the result of running the dimensionality reduction algorithms on audio recordings resulting in a 2D visualization of the dataset. Each data point is a short sample retrieved from audio. Spectrogram A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time. For each selected sample in the graph we plot spectogram of the respective audio. It allows further verification of similarity between samples as well as provide insights into frequency structure of the signal. Worflow example Tune the algorithm parameters or accept the defaults. Upload an audio file you want to analyse. If you don't have anything at hand, here is an audio that contains some bird calls, primarily storm petrels, recorded on St. Helena. Can you spot bird calls on the scatter plot? To download the recording, right-click on the link and select \"save link as...\" and then Upload it. Audio Explorer works with majority of popular audio formats, all thanks to sox . Play with the parameters, add / remove features and see how it influences the plot by clicking Apply . Click a point on the graph to hear the audio and see the spectrogram. Mind that what you hear and see is longer than selected Sample length by 0.4s . 0.2s margin is added to the beginning and end to get better impression of the sound surrounding. Calculated audio features can be inspected, sorted and filtered through custom-made query language by selecting Table tab. You can use the following expressions: <= , < , >= and > , e.g. > 2000 . Use Lasso select (top right menu that appears after hovering over the graph) to select interesting cluster. The selection will be reflected in Table . For the selected audio fragments a power spectrum will be plotted (units: Voltage 2 ), scaled to dB. Now that we have frequencies present in the selected fragments, user can decide to reduce presence of these frequencies in rest of the audio. Once you're happy with the selection, you can download the data from Table .","title":"Getting started"},{"location":"getting_started/#getting-started","text":"TODO - detailed walkthrough","title":"Getting started"},{"location":"getting_started/#explore","text":"Explanation of app sections.","title":"Explore"},{"location":"getting_started/#what-am-i-looking-at","text":"The scatter plot is the result of running the dimensionality reduction algorithms on audio recordings resulting in a 2D visualization of the dataset. Each data point is a short sample retrieved from audio.","title":"What am I looking at?"},{"location":"getting_started/#spectrogram","text":"A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time. For each selected sample in the graph we plot spectogram of the respective audio. It allows further verification of similarity between samples as well as provide insights into frequency structure of the signal.","title":"Spectrogram"},{"location":"getting_started/#worflow-example","text":"Tune the algorithm parameters or accept the defaults. Upload an audio file you want to analyse. If you don't have anything at hand, here is an audio that contains some bird calls, primarily storm petrels, recorded on St. Helena. Can you spot bird calls on the scatter plot? To download the recording, right-click on the link and select \"save link as...\" and then Upload it. Audio Explorer works with majority of popular audio formats, all thanks to sox . Play with the parameters, add / remove features and see how it influences the plot by clicking Apply . Click a point on the graph to hear the audio and see the spectrogram. Mind that what you hear and see is longer than selected Sample length by 0.4s . 0.2s margin is added to the beginning and end to get better impression of the sound surrounding. Calculated audio features can be inspected, sorted and filtered through custom-made query language by selecting Table tab. You can use the following expressions: <= , < , >= and > , e.g. > 2000 . Use Lasso select (top right menu that appears after hovering over the graph) to select interesting cluster. The selection will be reflected in Table . For the selected audio fragments a power spectrum will be plotted (units: Voltage 2 ), scaled to dB. Now that we have frequencies present in the selected fragments, user can decide to reduce presence of these frequencies in rest of the audio. Once you're happy with the selection, you can download the data from Table .","title":"Worflow example"}]}