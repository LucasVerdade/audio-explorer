{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Audio Explorer docs site! Audio Explorer helps in audio data discovery and labelling by utilising unsupervised and supervised machine learning - and good deal of statistics with digital signal processing.","title":"Home"},{"location":"#welcome-to-audio-explorer-docs-site","text":"Audio Explorer helps in audio data discovery and labelling by utilising unsupervised and supervised machine learning - and good deal of statistics with digital signal processing.","title":"Welcome to Audio Explorer docs site!"},{"location":"about/","text":"About Hi, I'm Lukasz! I am a software engineer and scientist. Why Audio Explorer? Manual labelling of audio is time consuming and error prone. With this tool we aim to augment user by allowing to easily navigate recordings and label selected audio pieces. Instead of looking at raw audio, we extract number of audio features from each sample. The latter typically consists of dozens of calculated values (features), which would be impossible to visualise (e.g. 20 features per sample effectively means 20-dimensional space). Audio Explorer allows to compute over 100 features per audio fragment. How do we achieve that? The program computes audio features per short fragments of submitted audio piece and then finds projection to 2-dimensional space by using linear or non-linear dimensionality reduction . Audio fragments are then represented as points; similar sample will be close together, while those which are different further apart. Acknowledgement My special thanks to: * AWS Cloud Credits for Research for supporting the project! Thanks to AWS I could rapidly prototype the models and the app itself. * My colleagues from RSPB who have supplied the audio recordings and supported along the way.","title":"About"},{"location":"about/#about","text":"Hi, I'm Lukasz! I am a software engineer and scientist.","title":"About"},{"location":"about/#why-audio-explorer","text":"Manual labelling of audio is time consuming and error prone. With this tool we aim to augment user by allowing to easily navigate recordings and label selected audio pieces. Instead of looking at raw audio, we extract number of audio features from each sample. The latter typically consists of dozens of calculated values (features), which would be impossible to visualise (e.g. 20 features per sample effectively means 20-dimensional space). Audio Explorer allows to compute over 100 features per audio fragment.","title":"Why Audio Explorer?"},{"location":"about/#how-do-we-achieve-that","text":"The program computes audio features per short fragments of submitted audio piece and then finds projection to 2-dimensional space by using linear or non-linear dimensionality reduction . Audio fragments are then represented as points; similar sample will be close together, while those which are different further apart.","title":"How do we achieve that?"},{"location":"about/#acknowledgement","text":"My special thanks to: * AWS Cloud Credits for Research for supporting the project! Thanks to AWS I could rapidly prototype the models and the app itself. * My colleagues from RSPB who have supplied the audio recordings and supported along the way.","title":"Acknowledgement"},{"location":"app_description/","text":"Audio Explorer Copyright 2019 Lukasz Tracewski Audio Explorer helps in audio data discovery and labelling by utilising unsupervised and supervised machine learning - and good deal of statistics with digital signal processing. The program computes audio features per short fragments of submitted audio piece and then finds projection to 2-dimensional space by using linear or non-linear dimensionality reduction . Audio fragments are then represented as points; similar sample will be close together, while those which are different further apart. User can click on a point to play the audio fragment and inspect resulting spectrogram . Why build it? Manual labelling of audio is time consuming and error prone. With this tool we aim to augment user by allowing to easily navigate recordings and label selected audio pieces. Instead of looking at raw audio, we extract number of audio features from each sample. The latter typically consists of dozens of calculated values (features), which would be impossible to visualise (e.g. 20 features per sample effectively means 20-dimensional space). Audio Explorer allows to compute over 100 features per audio fragment. Worflow Tune the algorithm parameters or accept the defaults. Upload an audio file you want to analyse. If you don't have anything at hand, here is an audio that contains some bird calls, primarily storm petrels, recorded on St. Helena. Can you spot bird calls on the scatter plot? To download the recording, right-click on the link and select \"save link as...\" and then Upload it. Audio Explorer works with majority of popular audio formats, all thanks to sox . Play with the parameters, add / remove features and see how it influences the plot by clicking Apply . Click a point on the graph to hear the audio and see the spectrogram. Mind that what you hear and see is longer than selected Sample length by 0.4s . 0.2s margin is added to the beginning and end to get better impression of the sound surrounding. Calculated audio features can be inspected, sorted and filtered through custom-made query language by selecting Table tab. You can use the following expressions: <= , < , >= and > , e.g. > 2000 . Use Lasso select (top right menu that appears after hovering over the graph) to select interesting cluster. The selection will be reflected in Table . For the selected audio fragments a power spectrum will be plotted (units: Voltage 2 ), scaled to dB. Now that we have frequencies present in the selected fragments, user can decide to reduce presence of these frequencies in rest of the audio. Once you're happy with the selection, you can download the data from Table . Audio features Given audio fragment, we compute the following features: * Frequency statistics: mean, median, first, third and inter quartile * Pitch statistics: mean, median, first, third and inter quartile * Chroma : short-term pitch profile * Linear Predictor Coefficients ( LPC ) * Line Spectral Frequency ( LSF ) coefficients * Mel-Frequency Cepstral Coefficients ( MFCC ) * Octave Band Signal Intensity (OBSI) * Spectral crest factor per band * Decrease: average spectral slope * Flatness: spectral flatness using the ratio between geometric and arithmetic mean * Flux: flux of spectrum between consecutives frames * Rolloff: frequency so that 99% of the energy is contained below * Variation: normalized correlation of spectrum between consecutive frames Don't know what to choose ? Accept the default. How do we solve the problem? We take the multidimensional space of computed audio features and project it to two dimensions, while retaining most of the information that describes the sample. Audio pieces that sound similar will be packed closely together, while those that sound quite different should be far apart. User can select cluster of similar-sounding samples and mark them. What am I looking at? The scatter plot is the result of running the dimensionality reduction algorithms on audio recordings resulting in a 2D visualization of the dataset. Each data point is a short sample retrieved from audio. Dimensionality reduction Dimensionality reduction techniques reduce number of variables by projecting them to a lower-dimensional space. The aim in our case is to retain as much as possible of original information, while enjoying exploration of the data in much in familiar 2D space. We're looking at following methods: * Uniform Manifold Approximation and Projection * t-Distributed Stochastic Neighbor embedding * Principal Component Analysis * Kernel Principal Component Analysis * Factor Analysis * Independent Component Analysis * Isomap: Isometric Mapping * Spectral embedding * Locally Linear Embedding Spectrogram A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time. For each selected sample in the graph we plot spectogram of the respective audio. It allows further verification of similarity between samples as well as provide insights into frequency structure of the signal.","title":"App description"},{"location":"app_description/#audio-explorer","text":"Copyright 2019 Lukasz Tracewski Audio Explorer helps in audio data discovery and labelling by utilising unsupervised and supervised machine learning - and good deal of statistics with digital signal processing. The program computes audio features per short fragments of submitted audio piece and then finds projection to 2-dimensional space by using linear or non-linear dimensionality reduction . Audio fragments are then represented as points; similar sample will be close together, while those which are different further apart. User can click on a point to play the audio fragment and inspect resulting spectrogram .","title":"Audio Explorer"},{"location":"app_description/#why-build-it","text":"Manual labelling of audio is time consuming and error prone. With this tool we aim to augment user by allowing to easily navigate recordings and label selected audio pieces. Instead of looking at raw audio, we extract number of audio features from each sample. The latter typically consists of dozens of calculated values (features), which would be impossible to visualise (e.g. 20 features per sample effectively means 20-dimensional space). Audio Explorer allows to compute over 100 features per audio fragment.","title":"Why build it?"},{"location":"app_description/#worflow","text":"Tune the algorithm parameters or accept the defaults. Upload an audio file you want to analyse. If you don't have anything at hand, here is an audio that contains some bird calls, primarily storm petrels, recorded on St. Helena. Can you spot bird calls on the scatter plot? To download the recording, right-click on the link and select \"save link as...\" and then Upload it. Audio Explorer works with majority of popular audio formats, all thanks to sox . Play with the parameters, add / remove features and see how it influences the plot by clicking Apply . Click a point on the graph to hear the audio and see the spectrogram. Mind that what you hear and see is longer than selected Sample length by 0.4s . 0.2s margin is added to the beginning and end to get better impression of the sound surrounding. Calculated audio features can be inspected, sorted and filtered through custom-made query language by selecting Table tab. You can use the following expressions: <= , < , >= and > , e.g. > 2000 . Use Lasso select (top right menu that appears after hovering over the graph) to select interesting cluster. The selection will be reflected in Table . For the selected audio fragments a power spectrum will be plotted (units: Voltage 2 ), scaled to dB. Now that we have frequencies present in the selected fragments, user can decide to reduce presence of these frequencies in rest of the audio. Once you're happy with the selection, you can download the data from Table .","title":"Worflow"},{"location":"app_description/#audio-features","text":"Given audio fragment, we compute the following features: * Frequency statistics: mean, median, first, third and inter quartile * Pitch statistics: mean, median, first, third and inter quartile * Chroma : short-term pitch profile * Linear Predictor Coefficients ( LPC ) * Line Spectral Frequency ( LSF ) coefficients * Mel-Frequency Cepstral Coefficients ( MFCC ) * Octave Band Signal Intensity (OBSI) * Spectral crest factor per band * Decrease: average spectral slope * Flatness: spectral flatness using the ratio between geometric and arithmetic mean * Flux: flux of spectrum between consecutives frames * Rolloff: frequency so that 99% of the energy is contained below * Variation: normalized correlation of spectrum between consecutive frames Don't know what to choose ? Accept the default.","title":"Audio features"},{"location":"app_description/#how-do-we-solve-the-problem","text":"We take the multidimensional space of computed audio features and project it to two dimensions, while retaining most of the information that describes the sample. Audio pieces that sound similar will be packed closely together, while those that sound quite different should be far apart. User can select cluster of similar-sounding samples and mark them.","title":"How do we solve the problem?"},{"location":"app_description/#what-am-i-looking-at","text":"The scatter plot is the result of running the dimensionality reduction algorithms on audio recordings resulting in a 2D visualization of the dataset. Each data point is a short sample retrieved from audio.","title":"What am I looking at?"},{"location":"app_description/#dimensionality-reduction","text":"Dimensionality reduction techniques reduce number of variables by projecting them to a lower-dimensional space. The aim in our case is to retain as much as possible of original information, while enjoying exploration of the data in much in familiar 2D space. We're looking at following methods: * Uniform Manifold Approximation and Projection * t-Distributed Stochastic Neighbor embedding * Principal Component Analysis * Kernel Principal Component Analysis * Factor Analysis * Independent Component Analysis * Isomap: Isometric Mapping * Spectral embedding * Locally Linear Embedding","title":"Dimensionality reduction"},{"location":"app_description/#spectrogram","text":"A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time. For each selected sample in the graph we plot spectogram of the respective audio. It allows further verification of similarity between samples as well as provide insights into frequency structure of the signal.","title":"Spectrogram"},{"location":"audio_embedding/","text":"Audio embedding Audio features Given audio fragment, thee following features are computed: * Frequency statistics: mean, median, first, third and inter quartile * Pitch statistics: mean, median, first, third and inter quartile * Chroma : short-term pitch profile * Linear Predictor Coefficients ( LPC ) * Line Spectral Frequency ( LSF ) coefficients * Mel-Frequency Cepstral Coefficients ( MFCC ) * Octave Band Signal Intensity (OBSI) * Spectral crest factor per band * Decrease: average spectral slope * Flatness: spectral flatness using the ratio between geometric and arithmetic mean * Flux: flux of spectrum between consecutives frames * Rolloff: frequency so that 99% of the energy is contained below * Variation: normalized correlation of spectrum between consecutive frames Dimensionality reduction Dimensionality reduction techniques reduce number of variables by projecting them to a lower-dimensional space. The aim in our case is to retain as much as possible of original information, while enjoying exploration of the data in much in familiar 2D space. We're looking at following methods: * Uniform Manifold Approximation and Projection * t-Distributed Stochastic Neighbor embedding * Principal Component Analysis * Kernel Principal Component Analysis * Factor Analysis * Independent Component Analysis * Isomap: Isometric Mapping * Spectral embedding * Locally Linear Embedding","title":"Audio embedding"},{"location":"audio_embedding/#audio-embedding","text":"","title":"Audio embedding"},{"location":"audio_embedding/#audio-features","text":"Given audio fragment, thee following features are computed: * Frequency statistics: mean, median, first, third and inter quartile * Pitch statistics: mean, median, first, third and inter quartile * Chroma : short-term pitch profile * Linear Predictor Coefficients ( LPC ) * Line Spectral Frequency ( LSF ) coefficients * Mel-Frequency Cepstral Coefficients ( MFCC ) * Octave Band Signal Intensity (OBSI) * Spectral crest factor per band * Decrease: average spectral slope * Flatness: spectral flatness using the ratio between geometric and arithmetic mean * Flux: flux of spectrum between consecutives frames * Rolloff: frequency so that 99% of the energy is contained below * Variation: normalized correlation of spectrum between consecutive frames","title":"Audio features"},{"location":"audio_embedding/#dimensionality-reduction","text":"Dimensionality reduction techniques reduce number of variables by projecting them to a lower-dimensional space. The aim in our case is to retain as much as possible of original information, while enjoying exploration of the data in much in familiar 2D space. We're looking at following methods: * Uniform Manifold Approximation and Projection * t-Distributed Stochastic Neighbor embedding * Principal Component Analysis * Kernel Principal Component Analysis * Factor Analysis * Independent Component Analysis * Isomap: Isometric Mapping * Spectral embedding * Locally Linear Embedding","title":"Dimensionality reduction"},{"location":"command_line/","text":"Command Line Interface audiocli is a command line program that helps in extracting audio features and diemnsionality reduction. It's primary purpose is to build offline embeddings for the Audio Explorer. User can create a model with large volume of audio data and then use it to embed new audio files into that space. Usage: audiocli.py [OPTIONS] COMMAND [ARGS]... Options: --quiet Run in a silent mode --help Show this message and exit. Commands: a2f Audio to HDF5 features f2m Features to embedding model m2e Model to embedddings Following options are available: a2f - Audio to Features Usage: audiocli.py a2f [OPTIONS] Audio to HDF5 features Options: -in, --input TEXT Path to audio in WAV format. [required] -out, --output TEXT Output file or directory. If directory does not exist it will be created. The output files will have the same base name as input. -j, --jobs INTEGER Number of jobs to run. Defaults to all cores [default: -1] -c, --config PATH Feature extractor config. -m, --multi Process audio files in parallel. The setting will produce an HDF5 file per input, with the same base name. Large memory footprint. If not set, a single output file will be produced. -f, --format [fixed|table] HDF5 format. Table is slightly slower and requires pytables (will not work outside Python), but allows to read specific columns. --help Show this message and exit. Example: python audiocli.py a2f --input /mnt/data/stormpetrels/ --output /mnt/data/h --config audioexplorer/algo_config.ini --format table --multi The program loads complete file into memory, so watch out for memory usage f2m - Features to Model Usage: audiocli.py f2m [OPTIONS] Features to embedding model Options: -in, --input TEXT Path to h5 features. [required] -out, --output TEXT Output directory. -j, --jobs INTEGER Number of jobs to run [default: -1] -a, --algo [umap|tsne|isomap|spectral|loclin|pca|kpca|fa|ica] Embedding to use -p, --grid PATH JSON with grid search parameters for the embedding algo --help Show this message and exit.","title":"Command Line Interface"},{"location":"command_line/#command-line-interface","text":"audiocli is a command line program that helps in extracting audio features and diemnsionality reduction. It's primary purpose is to build offline embeddings for the Audio Explorer. User can create a model with large volume of audio data and then use it to embed new audio files into that space. Usage: audiocli.py [OPTIONS] COMMAND [ARGS]... Options: --quiet Run in a silent mode --help Show this message and exit. Commands: a2f Audio to HDF5 features f2m Features to embedding model m2e Model to embedddings Following options are available:","title":"Command Line Interface"},{"location":"command_line/#a2f-audio-to-features","text":"Usage: audiocli.py a2f [OPTIONS] Audio to HDF5 features Options: -in, --input TEXT Path to audio in WAV format. [required] -out, --output TEXT Output file or directory. If directory does not exist it will be created. The output files will have the same base name as input. -j, --jobs INTEGER Number of jobs to run. Defaults to all cores [default: -1] -c, --config PATH Feature extractor config. -m, --multi Process audio files in parallel. The setting will produce an HDF5 file per input, with the same base name. Large memory footprint. If not set, a single output file will be produced. -f, --format [fixed|table] HDF5 format. Table is slightly slower and requires pytables (will not work outside Python), but allows to read specific columns. --help Show this message and exit. Example: python audiocli.py a2f --input /mnt/data/stormpetrels/ --output /mnt/data/h --config audioexplorer/algo_config.ini --format table --multi The program loads complete file into memory, so watch out for memory usage","title":"a2f - Audio to Features"},{"location":"command_line/#f2m-features-to-model","text":"Usage: audiocli.py f2m [OPTIONS] Features to embedding model Options: -in, --input TEXT Path to h5 features. [required] -out, --output TEXT Output directory. -j, --jobs INTEGER Number of jobs to run [default: -1] -a, --algo [umap|tsne|isomap|spectral|loclin|pca|kpca|fa|ica] Embedding to use -p, --grid PATH JSON with grid search parameters for the embedding algo --help Show this message and exit.","title":"f2m - Features to Model"},{"location":"developer_notes/","text":"Developer notes The web app is hosted on AWS. It scales to up to 3 instances and uses nginx load balancer. The traffic is secured and managed though Route 53. AWS provides a certificate too. The code repository contains complete load balancer configuration required to run the app in the wild. Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring. Set up development environment To set up your development environment, run the following commands: 1. Fork and clone the Audio Explorer repo . 2. Move into the clone: cd audio-explorer . 3. Create Anaconda environment: conda env create -f environment.yml . TODO Currently Audio Explorer uploads every upload to my S3. We need a local mode that will allow anyone to easily experiment and develop the code. Pull Request Guidelines Use the GitHub flow when proposing contributions to this repository (i.e. create a feature branch and submit a PR against the master branch). How to create pull request is discussed here .","title":"Developer notes"},{"location":"developer_notes/#developer-notes","text":"The web app is hosted on AWS. It scales to up to 3 instances and uses nginx load balancer. The traffic is secured and managed though Route 53. AWS provides a certificate too. The code repository contains complete load balancer configuration required to run the app in the wild. Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.","title":"Developer notes"},{"location":"developer_notes/#set-up-development-environment","text":"To set up your development environment, run the following commands: 1. Fork and clone the Audio Explorer repo . 2. Move into the clone: cd audio-explorer . 3. Create Anaconda environment: conda env create -f environment.yml .","title":"Set up development environment"},{"location":"developer_notes/#todo","text":"Currently Audio Explorer uploads every upload to my S3. We need a local mode that will allow anyone to easily experiment and develop the code.","title":"TODO"},{"location":"developer_notes/#pull-request-guidelines","text":"Use the GitHub flow when proposing contributions to this repository (i.e. create a feature branch and submit a PR against the master branch). How to create pull request is discussed here .","title":"Pull Request Guidelines"},{"location":"getting_started/","text":"Getting started Here I will put detailed walkthrough. Worflow example Tune the algorithm parameters or accept the defaults. Upload an audio file you want to analyse. If you don't have anything at hand, here is an audio that contains some bird calls, primarily storm petrels, recorded on St. Helena. Can you spot bird calls on the scatter plot? To download the recording, right-click on the link and select \"save link as...\" and then Upload it. Audio Explorer works with majority of popular audio formats, all thanks to sox . Play with the parameters, add / remove features and see how it influences the plot by clicking Apply . Click a point on the graph to hear the audio and see the spectrogram. Mind that what you hear and see is longer than selected Sample length by 0.4s . 0.2s margin is added to the beginning and end to get better impression of the sound surrounding. Calculated audio features can be inspected, sorted and filtered through custom-made query language by selecting Table tab. You can use the following expressions: <= , < , >= and > , e.g. > 2000 . Use Lasso select (top right menu that appears after hovering over the graph) to select interesting cluster. The selection will be reflected in Table . For the selected audio fragments a power spectrum will be plotted (units: Voltage 2 ), scaled to dB. Now that we have frequencies present in the selected fragments, user can decide to reduce presence of these frequencies in rest of the audio. Once you're happy with the selection, you can download the data from Table .","title":"Getting started"},{"location":"getting_started/#getting-started","text":"Here I will put detailed walkthrough.","title":"Getting started"},{"location":"getting_started/#worflow-example","text":"Tune the algorithm parameters or accept the defaults. Upload an audio file you want to analyse. If you don't have anything at hand, here is an audio that contains some bird calls, primarily storm petrels, recorded on St. Helena. Can you spot bird calls on the scatter plot? To download the recording, right-click on the link and select \"save link as...\" and then Upload it. Audio Explorer works with majority of popular audio formats, all thanks to sox . Play with the parameters, add / remove features and see how it influences the plot by clicking Apply . Click a point on the graph to hear the audio and see the spectrogram. Mind that what you hear and see is longer than selected Sample length by 0.4s . 0.2s margin is added to the beginning and end to get better impression of the sound surrounding. Calculated audio features can be inspected, sorted and filtered through custom-made query language by selecting Table tab. You can use the following expressions: <= , < , >= and > , e.g. > 2000 . Use Lasso select (top right menu that appears after hovering over the graph) to select interesting cluster. The selection will be reflected in Table . For the selected audio fragments a power spectrum will be plotted (units: Voltage 2 ), scaled to dB. Now that we have frequencies present in the selected fragments, user can decide to reduce presence of these frequencies in rest of the audio. Once you're happy with the selection, you can download the data from Table .","title":"Worflow example"}]}